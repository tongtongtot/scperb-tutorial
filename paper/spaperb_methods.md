# SpaPerb

SpaPerb, equipped with the variational auto-encoders to estimate the latent content variable, and the dataset-related style, generate new samples from the control and stimulus dataset:
$$
\begin{gather}
Z_{ctrl}=E(X_{ctrl})\\
Z_{stim}=E(X_{stim})\\
\end{gather}
$$

Then we applied the decoder to generate the new data sample based on the extracted feature:
SpaPerb aims to transfer the gene expressions from the control dataset to the stimulus dataset. 

There are two ways to achieve this aim. 

The first way is to make the latent representation of the control and stimulus data as close as possible. Inspired by the style transfer GAN, we style-transferred the latent representation of the control data into stimulus data. We add a delta vector $Z_{delta}$ to the $Z_{ctrl}$ to achieve the goal. The delta vector $Z_{delta}$ is generated by projecting a delta vector $V_{delta}$ from a delta encoder $E_{delta}$. By using a delta encoder, $Z_{delta}$ is able to learn the difference between $Z_{ctrl}$ and $Z_{stimulated}$ much better than using a constant vector. Finally, to decrease the bias of the delta vector, $V_{delta}$ is generated by randomly choosing values that ranged $(0,1)$ instead of using a vector with constant values. 

Therefore, the process is shown below:
$$
\begin{gather}
V_{delta} = random(input_-size)\\  
Z_{delta}=E^{delta}(V_{delta})\\  
X_{stim}'=D(Z_{ctrl} + Z_{delta})\\  
L_{delta} = criterion(Z_{delta}, (Z_{stim}-Z_{ctrl}))\\
\end{gather}
$$

Another way is to make the generated image similar to the stimulus dataset. 

This process differs from the original VAE and other methods. As these methods apply a reconstruction loss, that is, to compute a loss between $X_{ctrl},X_{ctrl}'$ and $X_{stim},X_{stim}'$. 

In this case, there are two losses:
$$
\begin{gather}
X_{ctrl}'=D(Z_{ctrl}) \\  
X_{stim}'=D(Z_{stim}) \\  
L_{ctrl}=criterion(X_{ctrl}, X_{ctrl}')\\  
L_{stim}=criterion(X_{stim}, X_{stim}')\\
\end{gather}
$$
However, in this case, we want to emphasize the style transfer from $X_{ctrl}$ to $X_{stim}$, the reconstructed data $X_{stimulated}'$ should be similar to the original data $X_{stimulated}$, so the reconstruction loss will be:
$$
\begin{gather}
X_{stim}'=D(Z_{ctrl}) \\  
L_{reconstruction}=criterion(X_{stim}, X_{stim}')\\
\end{gather}
$$
In our model, SpaPerb, we combine these two methods above and generated a better result than only using one of these models. In our model, we first randomly chose a vector $V_{delta}$ with a size of input from $(0,1)$; then project it through a delta encoder $E_{delta}$ to get the latent representation of the difference between control and stimulus datasets; finally, we compute a reconstruction loss between the generated and the real stimulus images. 

Then by using VAE, we need to know the possibility curve of the graph; that is, we need to maximize $\displaystyle\sum_{x} P(x)$, or in other words, $\displaystyle\sum_x log(P(x))$.

Therefore, we have to transform this equation to solve this problem. Here, we create a new function $f$ to help us better achieve the goal:
$$
\begin{align*}
log(P(x)) =& \ log(P(x)) \times \displaystyle\int f(z|x)dz \\
=& \ \displaystyle\int f(z|x)\times log(\frac{P(z,x)}{P(z|x)}) dz \\
=& \ \displaystyle\int f(z|x)\times log(\frac{P(z,x)\times f(z|x)}{f(z|x) \times P(z|x)})dz \\
=& \ \displaystyle\int f(z|x)\times log(\frac{P(z,x)}{f(z|x)}) dz \ + \displaystyle\int f(z|x)\times log(\frac{f(z|x)}{P(z|x)}) dz\\
=& \ \displaystyle\int f(z|x)\times log(\frac{P(z,x)}{f(z|x)}) dz \ + KLD(f(z|x)||P(z|x))\\
\end{align*}
$$
In this case, as $KLD(f(z|x)||P(z|x)) \ge 0$,  $log(P(x)) \ge \displaystyle\int f(z|x)\times log(\frac{P(z,x)}{f(z|x)}) dz$.

Also, as $P(x) = \displaystyle\int P(x|z)P(z)dz$, $P(x)$ is independent to $f(x)$, so when optimizing $f(z|x)$ to minimize $KLD(f(z|x)||P(z|x))$, the $log(P(x))$ will gradually become closer to $\displaystyle\int f(z|x)\times log(\frac{P(z,x)}{f(z|x)}) dz$, or in other words, the lower bound of $log(P(x))$.

Therefore, in order to maximize $log(P(x))$, we need to maximize the lower bound $\displaystyle\int f(z|x)\times log(\frac{P(z,x)}{f(z|x)}) dz$.

To maximize the lower bound, we need further processing:
$$
\begin{align*}
Lowerbound =& \displaystyle\int f(z|x)\times log(\frac{P(z,x)}{f(z|x)}) dz\\
=& \displaystyle\int f(z|x)\times log(\frac{P(x|z)\times P(z)}{f(z|x)}) dz\\
=& -\displaystyle\int f(z|x)\times log(\frac{f(z|x)}{P(x|z)}) dz \ + \displaystyle\int f(z|x)\times log(\frac{P(z)}{f(z|x)}) dz\\
=& -KLD(f(z|x)||P(z))\ + E_{f(z|x)}[log(P(x|z))]
\end{align*}
$$
Therefore, $log(P(x)) = KLD(f(z|x)||P(z|x))- KLD(f(z|x)||P(z)) + E_{f(z|x)}[log(P(x|z))]$.

By transforming the equation above, we can get the final equation to compute the loss for the model.
$$
\begin{align*}
log(P(x)) - KLD(f(z|x)||P(z|x)) =& - KLD(f(z|x)||P(z)) + E_{f(z|x)}[log(P(x|z))]\\
=& \ ELBO\\
\end{align*}
$$
And our goal is to construct a neural network to compute a function f to maximize ELBO.

By setting a prior distribution $P(z)$ as a normal distribution $N(0,1)$, we can use a neuro network to generate $\mu$ and $\sigma$ of $f(z|x)$ and maximizing the KLD part of the ELBO by using a Kullback-Leibler divergence $L_{KL} =  - KLD(N(\mu,\sigma),N(0,I))$; Maximizing the reconstruction loss $L_{reconstruct}$ will maximize the rest part of the ELBO.

As a result, the total loss of SpaPerb will be:
$$
Loss = w1 \times L_{latent} + w2 \times L_{reconstruct} + w3\times L_{KL}
$$
In SpaPerb the weight sets up as the following: $w1=100,w2=100,w3=0.5$.

Overall, the process works as the following:
$$
\begin{gather}
V_{delta} = random(input_-size)\\  
Z_{delta}=E^{delta}(V_{delta})\\  
Z_{ctrl}=E(X_{ctrl}) \\  
Z_{stim}=E(X_{stim}) \\  
Z_{stim}'=Z_{ctrl} + Z_{delta}\\  
X_{stim}'=D(Z_{stim}')\\  
L_{delta} = Smooth_-L1Loss(Z_{delta}, (Z_{stim}-Z_{ctrl}))\\  
L_{reconstruction} = Smooth_-L1Loss(X_{stim}, X_{stim}')\\  
L_{KL} = KLD(P_x, N(0,1))\\  
Loss=100 \times L_{reconstruct} + 100 \times L_{latent} + 0.5\times L_{KL}\\
\end{gather}
$$


# Datasets and preprocessing: 

Mohammad et al. included three groups of control and stimulated cells: two groups of PBMC cells, and a group of HPOLY cells. Mohammad et al. preprocessed the data by removing megakaryocytic cells, filtering the cells with a minimum of 500 expressing cells, extracting the top 6998 cells, and log-transforming the original data. All the data are available on https://github.com/theislab/scgen-reproducibility.

In our model, we performed further data preprocessing to ensure consistency between control and stimulus cells within each cell type. Specifically, for each cell type, we randomly selected an equal number of cells from both the control and stimulated groups and used them to balance the dataset. This data preprocessing step helped us create a more robust and unbiased dataset, enabling accurate and fair comparisons between the control and stimulus conditions within each cell type during subsequent analyses. By doing such data processing, we guarantee that each pair of $X_{ctrl}$ and $X_{stim}$ have the same cell type, so the following style transfer process would be valid. 

#  Results and statistics

In SpaPerb, we evaluated the performance of our model using the square of the $r_-value$, which is calculated by the $scipy.stats.linregress$ function. This metric measures the correlation between the generated images and the ground truth data. We computed the $r_-square$ values for both the mean and variance of all genes, as well as for the top 100 Differentially Expressed Genes (DEGs).

To gain a visual understanding of the model's results, we created scatter plots （注：就是左下角的图片，名字存疑） comparing the generated images to the corresponding ground truth data. This graph allowed us to observe how well the model's predictions aligned with the actual values.

Additionally, we investigated the differences between the generated images and the ground truth data for the top DEG using a violin plot. The DEGs were identified using the $scanpy.tl.rank_-genes_-groups$ function, employing the Wilcoxon method.

Through these analyses, we aimed to assess the accuracy and performance of our SpaPerb model in generating realistic images based on the input gene expression data. The evaluation of $r_-square$ values and the visualization of the scatter and violin plots provided valuable insights into the model's capabilities and highlighted any discrepancies between the generated and true data for further investigation.
